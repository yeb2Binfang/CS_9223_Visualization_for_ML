{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating epochs and generating evoked responses (ERP/ERF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "import matplotlib\n",
    "\n",
    "import mne\n",
    "import mne_bids\n",
    "\n",
    "matplotlib.use('Qt5Agg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opening raw data file out_data\\sample_BIDS\\sub-01\\ses-01\\meg\\sub-01_ses-01_task-audiovisual_run-01_meg.fif...\n",
      "    Read a total of 3 projection items:\n",
      "        PCA-v1 (1 x 102)  idle\n",
      "        PCA-v2 (1 x 102)  idle\n",
      "        PCA-v3 (1 x 102)  idle\n",
      "    Range : 25800 ... 192599 =     42.956 ...   320.670 secs\n",
      "Ready.\n",
      "Reading events from out_data\\sample_BIDS\\sub-01\\ses-01\\meg\\sub-01_ses-01_task-audiovisual_run-01_events.tsv.\n",
      "Reading channel info from out_data\\sample_BIDS\\sub-01\\ses-01\\meg\\sub-01_ses-01_task-audiovisual_run-01_channels.tsv.\n",
      "Reading 0 ... 166799  =      0.000 ...   277.714 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-3-34cfe67f8f23>:9: RuntimeWarning: The unit for channel(s) STI 001, STI 002, STI 003, STI 004, STI 005, STI 006, STI 014, STI 015, STI 016 has changed from V to NA.\n",
      "  raw = mne_bids.read_raw_bids(bids_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 0.1 - 40 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 0.10\n",
      "- Lower transition bandwidth: 0.10 Hz (-6 dB cutoff frequency: 0.05 Hz)\n",
      "- Upper passband edge: 40.00 Hz\n",
      "- Upper transition bandwidth: 10.00 Hz (-6 dB cutoff frequency: 45.00 Hz)\n",
      "- Filter length: 19821 samples (33.001 sec)\n",
      "\n",
      "Used Annotations descriptions: ['Auditory/Left', 'Auditory/Right', 'Button', 'Smiley', 'Visual/Left', 'Visual/Right']\n"
     ]
    }
   ],
   "source": [
    "bids_root = pathlib.Path('out_data/sample_BIDS')\n",
    "\n",
    "bids_path = mne_bids.BIDSPath(subject='01',\n",
    "                             session='01',\n",
    "                             task='audiovisual',\n",
    "                             run='01',\n",
    "                             root=bids_root)\n",
    "\n",
    "raw = mne_bids.read_raw_bids(bids_path)\n",
    "raw.load_data()\n",
    "raw.filter(l_freq=0.1,h_freq=40)\n",
    "events,event_id=mne.events_from_annotations(raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Auditory/Left': 1,\n",
       " 'Auditory/Right': 2,\n",
       " 'Button': 3,\n",
       " 'Smiley': 4,\n",
       " 'Visual/Left': 5,\n",
       " 'Visual/Right': 6}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "event_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not setting metadata\n",
      "Not setting metadata\n",
      "320 matching events found\n",
      "Setting baseline interval to [-0.2996928197375818, 0.0] sec\n",
      "Applying baseline correction (mode: mean)\n",
      "Created an SSP operator (subspace dimension = 3)\n",
      "3 projection items activated\n",
      "Loading data for 320 events and 481 original time points ...\n",
      "0 bad epochs dropped\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Epochs |  320 events (all good), -0.299693 - 0.499488 sec, baseline [-0.299693, 0] sec, ~444.8 MB, data loaded,\n",
       " 'Auditory/Left': 72\n",
       " 'Auditory/Right': 73\n",
       " 'Button': 16\n",
       " 'Smiley': 15\n",
       " 'Visual/Left': 73\n",
       " 'Visual/Right': 71>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmin = -0.3\n",
    "tmax = 0.5\n",
    "baseline = (None, 0)\n",
    "\n",
    "epochs = mne.Epochs(raw,\n",
    "                   events=events,\n",
    "                   event_id=event_id,\n",
    "                   tmin=tmin,\n",
    "                   tmax=tmax,\n",
    "                   baseline=baseline,\n",
    "                   preload=True)\n",
    "epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<MNEBrowseFigure size 1920x1001 with 4 Axes>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped 0 epochs: \n",
      "Channels marked as bad: ['MEG 2443', 'EEG 053']\n"
     ]
    }
   ],
   "source": [
    "epochs.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercise:\n",
    "* Create epochs starting 250 ms before the stimulus onset and ending 800 ms after stimulus onset, and apply baseline correction with a baseline period ranging from -200 to 0 ms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selecting epochs based on experimental conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Epochs |  73 events (all good), -0.299693 - 0.499488 sec, baseline [-0.299693, 0] sec, ~104.0 MB, data loaded,\n",
       " 'Auditory/Right': 73>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epochs['Auditory/Right']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Epochs |  145 events (all good), -0.299693 - 0.499488 sec, baseline [-0.299693, 0] sec, ~203.4 MB, data loaded,\n",
       " 'Auditory/Left': 72\n",
       " 'Auditory/Right': 73>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epochs['Auditory']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Epochs |  145 events (all good), -0.299693 - 0.499488 sec, baseline [-0.299693, 0] sec, ~203.4 MB, data loaded,\n",
       " 'Auditory/Left': 72\n",
       " 'Visual/Left': 73>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epochs['Left']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not setting metadata\n",
      "Not setting metadata\n",
      "144 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "0 bad epochs dropped\n",
      "Not setting metadata\n",
      "Not setting metadata\n",
      "144 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "0 bad epochs dropped\n",
      "Not setting metadata\n",
      "Not setting metadata\n",
      "144 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "0 bad epochs dropped\n",
      "combining channels using \"gfp\"\n",
      "combining channels using \"gfp\"\n",
      "combining channels using \"gfp\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<Figure size 640x480 with 3 Axes>,\n",
       " <Figure size 640x480 with 3 Axes>,\n",
       " <Figure size 640x480 with 3 Axes>]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epochs['Visual'].plot_image()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercise:\n",
    "* Extract all epochs with a \"right\" condition, and plot the ERP imgae for the EEG channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing projector <Projection | PCA-v1, active : True, n_channels : 102>\n",
      "Removing projector <Projection | PCA-v2, active : True, n_channels : 102>\n",
      "Removing projector <Projection | PCA-v3, active : True, n_channels : 102>\n",
      "Not setting metadata\n",
      "Not setting metadata\n",
      "144 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "0 bad epochs dropped\n",
      "combining channels using \"gfp\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<Figure size 640x480 with 3 Axes>]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epochs['Right'].copy().pick_types(meg=False,eeg=True).plot_image()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs.save(pathlib.Path('out_data') / 'epochs_epo.fif',overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating evoked data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "evoked_auditory = epochs['Auditory'].average()\n",
    "evoked_visual = epochs['Visual'].average()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Evoked | '0.50 * Auditory/Left + 0.50 * Auditory/Right' (average, N=145), [-0.29969, 0.49949] sec, 366 ch, ~4.6 MB>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evoked_auditory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x500 with 6 Axes>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evoked_auditory.plot(spatial_colors=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 900x195 with 6 Axes>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evoked_auditory.plot_topomap(ch_type='mag',times=[0,0.050,0.100,0.150,0.200])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Projections have already been applied. Setting proj attribute to True.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 800x420 with 7 Axes>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evoked_auditory.plot_joint(picks='mag')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "combining channels using \"gfp\"\n",
      "combining channels using \"gfp\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<Figure size 800x600 with 1 Axes>]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mne.viz.plot_compare_evokeds([evoked_auditory,evoked_visual],picks='mag')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercise:\n",
    "* Plot a GFP comparison for the \"Visual/Left\" and \"Visual/Right\" conditions of the EEG data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving evoked data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "mne.write_evokeds(fname=pathlib.Path('out_data') / 'evokeds_ave.fif',\n",
    "                 evoked=[evoked_auditory,evoked_visual])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading evoked data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading out_data\\evokeds_ave.fif ...\n",
      "    Read a total of 3 projection items:\n",
      "        PCA-v1 (1 x 102) active\n",
      "        PCA-v2 (1 x 102) active\n",
      "        PCA-v3 (1 x 102) active\n",
      "    Found the data of interest:\n",
      "        t =    -299.69 ...     499.49 ms (0.50 * Auditory/Left + 0.50 * Auditory/Right)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 145 - aspect type = 100\n",
      "Projections have already been applied. Setting proj attribute to True.\n",
      "No baseline correction applied\n",
      "    Read a total of 3 projection items:\n",
      "        PCA-v1 (1 x 102) active\n",
      "        PCA-v2 (1 x 102) active\n",
      "        PCA-v3 (1 x 102) active\n",
      "    Found the data of interest:\n",
      "        t =    -299.69 ...     499.49 ms (0.51 * Visual/Left + 0.49 * Visual/Right)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 144 - aspect type = 100\n",
      "Projections have already been applied. Setting proj attribute to True.\n",
      "No baseline correction applied\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<Evoked | '0.50 * Auditory/Left + 0.50 * Auditory/Right' (average, N=145), [-0.29969, 0.49949] sec, 366 ch, ~4.6 MB>,\n",
       " <Evoked | '0.51 * Visual/Left + 0.49 * Visual/Right' (average, N=144), [-0.29969, 0.49949] sec, 366 ch, ~4.6 MB>]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evokeds = mne.read_evokeds(fname=pathlib.Path('out_data')/'evokeds_ave.fif')\n",
    "evokeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Evoked | '0.50 * Auditory/Left + 0.50 * Auditory/Right' (average, N=145), [-0.29969, 0.49949] sec, 366 ch, ~4.6 MB>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evokeds[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading out_data\\evokeds_ave.fif ...\n",
      "    Read a total of 3 projection items:\n",
      "        PCA-v1 (1 x 102) active\n",
      "        PCA-v2 (1 x 102) active\n",
      "        PCA-v3 (1 x 102) active\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "condition \"0.50 * Visual/Left + 0.50 * Visual/Right\" (average) not found, out of found datasets:\n\"0.50 * Auditory/Left + 0.50 * Auditory/Right\" (average)\n\"0.51 * Visual/Left + 0.49 * Visual/Right\" (average)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-29-09617788f69f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m evoked = mne.read_evokeds(fname=pathlib.Path('out_data') / 'evokeds_ave.fif',\n\u001b[0m\u001b[0;32m      2\u001b[0m                          condition='0.50 * Visual/Left + 0.50 * Visual/Right')\n\u001b[0;32m      3\u001b[0m \u001b[0mevoked\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<decorator-gen-188>\u001b[0m in \u001b[0;36mread_evokeds\u001b[1;34m(fname, condition, baseline, kind, proj, allow_maxshield, verbose)\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\mne\\evoked.py\u001b[0m in \u001b[0;36mread_evokeds\u001b[1;34m(fname, condition, baseline, kind, proj, allow_maxshield, verbose)\u001b[0m\n\u001b[0;32m    972\u001b[0m         \u001b[0mreturn_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    973\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 974\u001b[1;33m     out = [Evoked(fname, c, kind=kind, proj=proj,\n\u001b[0m\u001b[0;32m    975\u001b[0m                   \u001b[0mallow_maxshield\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mallow_maxshield\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    976\u001b[0m                   verbose=verbose).apply_baseline(baseline)\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\mne\\evoked.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    972\u001b[0m         \u001b[0mreturn_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    973\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 974\u001b[1;33m     out = [Evoked(fname, c, kind=kind, proj=proj,\n\u001b[0m\u001b[0;32m    975\u001b[0m                   \u001b[0mallow_maxshield\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mallow_maxshield\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    976\u001b[0m                   verbose=verbose).apply_baseline(baseline)\n",
      "\u001b[1;32m<decorator-gen-184>\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, fname, condition, proj, kind, allow_maxshield, verbose)\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\mne\\evoked.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, fname, condition, proj, kind, allow_maxshield, verbose)\u001b[0m\n\u001b[0;32m    123\u001b[0m         \u001b[1;31m# Read the requested data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    124\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnave\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_aspect_kind\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcomment\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtimes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 125\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_read_evoked\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcondition\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkind\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mallow_maxshield\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    126\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_update_first_last\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    127\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mverbose\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\mne\\evoked.py\u001b[0m in \u001b[0;36m_read_evoked\u001b[1;34m(fname, condition, kind, allow_maxshield)\u001b[0m\n\u001b[0;32m   1011\u001b[0m             \u001b[0mfound_cond\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgoods\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1012\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfound_cond\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1013\u001b[1;33m                 raise ValueError('condition \"%s\" (%s) not found, out of '\n\u001b[0m\u001b[0;32m   1014\u001b[0m                                  \u001b[1;34m'found datasets:\\n%s'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1015\u001b[0m                                  % (condition, kind, t))\n",
      "\u001b[1;31mValueError\u001b[0m: condition \"0.50 * Visual/Left + 0.50 * Visual/Right\" (average) not found, out of found datasets:\n\"0.50 * Auditory/Left + 0.50 * Auditory/Right\" (average)\n\"0.51 * Visual/Left + 0.49 * Visual/Right\" (average)"
     ]
    }
   ],
   "source": [
    "evoked = mne.read_evokeds(fname=pathlib.Path('out_data') / 'evokeds_ave.fif',\n",
    "                         condition='0.50 * Visual/Left + 0.50 * Visual/Right')\n",
    "evoked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
